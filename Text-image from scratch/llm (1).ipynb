{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install diffusers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 \n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "NUM_GENERATE_IMAGES = 9\n",
    "NUM_TIMESTEPS = 1000\n",
    "MIXED_PRECISION = \"fp16\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggan/smithsonian_butterflies_subset\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, image in enumerate(dataset[:4][\"image\"]):\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "[\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(examples):\n",
    "    images = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return {\"images\": images}\n",
    "\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2DModel(\n",
    "    sample_size=IMG_SIZE,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\"\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\"\n",
    "    )\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = dataset[0][\"images\"].unsqueeze(0).to(device)\n",
    "print(\"Input shape\", sample_image.shape)\n",
    "print(\"Output shape\", model(sample_image, timestep=0).sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n",
    "noise = torch.randn(sample_image.shape).to(device)\n",
    "timesteps = torch.LongTensor([50]).to(device)\n",
    "noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)\n",
    "\n",
    "Image.fromarray(((noisy_image.permute(0, 2, 3, 1) + 1.0) * 127.5).type(torch.uint8).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred = model(noisy_image, timesteps).sample\n",
    "loss = F.mse_loss(noise_pred, noise)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image_generation(model, noise_scheduler, num_generate_images, random_seed, num_timesteps):\n",
    "    pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "\n",
    "    images = pipeline(\n",
    "        batch_size=num_generate_images,\n",
    "        generator=torch.manual_seed(random_seed),\n",
    "        num_inference_steps=num_timesteps\n",
    "    ).images\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(1, num_generate_images+1):\n",
    "        fig.add_subplot(3, 3, i)\n",
    "        plt.imshow(images[i-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(train_dataloader)*NUM_EPOCHS\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=MIXED_PRECISION,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS\n",
    ")\n",
    "\n",
    "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(model, optimizer, train_dataloader, lr_scheduler)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in tqdm(range(NUM_EPOCHS), position=0, leave=True):\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        clean_images = batch[\"images\"].to(device)\n",
    "        noise = torch.randn(clean_images.shape).to(device)\n",
    "        last_batch_size = len(clean_images)\n",
    "\n",
    "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (last_batch_size,)).to(device)\n",
    "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "        with accelerator.accumulate(model):\n",
    "            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss = train_running_loss / (idx+1)\n",
    "\n",
    "    train_learning_rate = lr_scheduler.get_last_lr()[0]\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH: {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Train Learning Rate EPOCH: {epoch+1}: {train_learning_rate}\")\n",
    "    if epoch%10 == 0:\n",
    "        sample_image_generation(model, noise_scheduler, NUM_GENERATE_IMAGES, RANDOM_SEED, NUM_TIMESTEPS)\n",
    "    print(\"-\"*30)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_generation(model, noise_scheduler, NUM_GENERATE_IMAGES, RANDOM_SEED, NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
